{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import re as re\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import GradientBoostedTrees, GradientBoostedTreesModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "######## SU's code for sampling #############\n",
    "\n",
    "# read directory of files and return a list of all driverIDs from csv's insid directory\n",
    "def get_drivers(dirpath):\n",
    "    \"\"\"\n",
    "    :param dirpath: string, path to directory containing driver csv's\n",
    "    :return: list, contains all driverIDs as strings\n",
    "    \"\"\"\n",
    "    try:\n",
    "        allfiles = os.listdir(dirpath)\n",
    "        drivers = [re.sub(r'[^0-9]', '', i) for i in allfiles]\n",
    "        drivers.remove('')\n",
    "        return drivers\n",
    "    except Exception as e:\n",
    "        print e\n",
    "\n",
    "# produces random samples of driverIDs and tripIDs in two separate lists\n",
    "def random_samples(targ_driv, driv_list, K=200):\n",
    "    \"\"\"\n",
    "    :param targ_driv: str, driverID we want to make false trips for\n",
    "    :param driv_list: list, list of all drivers, produced by get_drivers()\n",
    "    :param K: number of trips we want to make for targ_driv\n",
    "    :return: tuple of lists, first list is random driverIDs, second list is list of tripIDs, both are strings\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driv_list.remove(targ_driv) #removes the target driver from list of drivers to sample from\n",
    "        drivers = np.random.choice(driv_list, K, True)\n",
    "        trips = np.random.choice(np.arange(1,K+1).astype(str), K, True)\n",
    "        return (drivers, trips)\n",
    "    except Exception as e:\n",
    "        print e\n",
    "\n",
    "# reads directory of files and returns RDD of observations from trips in the sample (driverID, tripID combo)\n",
    "# NOTE: this function is VERY SLOW, it is what slows the entire workflow down\n",
    "def sample_data(path, driverIDs, tripIDs):\n",
    "    \"\"\"\n",
    "    :param path: string, path to directory containing driver.csv's\n",
    "    :param driverIDs: list, list of randomly sampled driverIDs as strings, produced by random_sample()\n",
    "    :param tripIDs: list, list of randomly sampled tripIDs as strings, produced by random_samples()\n",
    "        NOTE: the above two zip into a list of (driverID, tripID) tuples, with each tuple being a single item in the\n",
    "        sample\n",
    "    :return: RDD, contains only observations from the sample\n",
    "    \"\"\"\n",
    "    try:\n",
    "        combos = zip(driverIDs, tripIDs)\n",
    "        samplefiles = [path + '/' + 'driver_' + i + '.csv' for i in driverIDs]\n",
    "        samplefiles = ','.join(set(samplefiles))  #### NOTE: this set() action is a hack for small num. files\n",
    "        RDD = sc.textFile(samplefiles)   #### NOTE: with large num. files, might need to set num. partitions\n",
    "        RDDsplit = RDD.map(lambda x: x.split(','))\n",
    "        RDDsamples = RDDsplit.filter(lambda x: (x[2],x[3]) in combos)\n",
    "        RDDsamples.cache()\n",
    "        return RDDsamples\n",
    "    except Exception as e:\n",
    "        print e\n",
    "\n",
    "# takes RDD of samples and assigns new driverID and tripID to observations in a new RDD\n",
    "def ID_Data(targ_driver, RDD, K = 200):\n",
    "    \"\"\"\n",
    "    :param targ_driver: string, target driver we used to generate samples\n",
    "    :param RDD: RDD, trip data RDD produced by sample_data(), format will be original form (x,y,driverID,tripID,step)\n",
    "    :param K: int, number of trips we sampled\n",
    "    :return: RDD, in original format, but with driverID and tripID changed to look like new observations of the target\n",
    "    driver\n",
    "    \"\"\"\n",
    "    try:\n",
    "        newID1 = [targ_driver] * K\n",
    "        newID2 = np.arange(200, 201+K).astype(str)\n",
    "        newID = zip(newID1, newID2)\n",
    "        oldID = RDD.map(lambda x: (x[2],x[3])).distinct().collect()\n",
    "        glossary = sc.parallelize(zip(oldID, newID))\n",
    "        newRDD = RDD.map(lambda x: ((x[2],x[3]), ([x[0],x[1],x[4]]))).join(glossary)\n",
    "        newID_RDD = newRDD.map(lambda x: (x[1][0][0], x[1][0][1], x[1][1][0], x[1][1][1], x[1][0][2]))\n",
    "        return newID_RDD\n",
    "    except Exception as e:\n",
    "        print e\n",
    "\n",
    "\n",
    "# takes RDD in original form and converts it into key-value tuple with values being x,y,step,label\n",
    "def processRDD(RDD, label):\n",
    "    \"\"\"\n",
    "    :param RDD: RDD in original format (x,y,driverID,tripID,step)\n",
    "    :param label: category of observation, 1 for positive, 0 for negative\n",
    "    # note, not sure if it needs to be int or float\n",
    "    :return: RDD, RDD returned in new key/value format: (driverID, tripID), (x, y, step, label)\n",
    "    # note, x, y, step, and label will be floats\n",
    "    \"\"\"\n",
    "    try:\n",
    "        newRDD = RDD.map(lambda x: ((x[2],x[3]),(float(x[0]),float(x[1]),float(x[4]),label)))\n",
    "        return newRDD\n",
    "    except Exception as e:\n",
    "        print e\n",
    "\n",
    "# takes a driver to target, path to directory of driver.csv's, and returns an RDD labeled with\n",
    "# (driverID, tripID),(x,y,step,label), where a label 1 is from an actual trip, and label 0 is from\n",
    "# a trip randomly sampled from other drivers\n",
    "def labelRDDs(targ_driv, path, K=200):\n",
    "    \"\"\"\n",
    "    :param targ_driv: string, driver we want to create positive and negative labeled data for\n",
    "    :param path: string, path to directory where driver.csvs are stored\n",
    "    :param K: int, number of negative (manufactured) trips to sample\n",
    "    :return: RDD with key, value tuple where key is (driverID, tripID) and value is (x,y,step,label)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        full_path = path + '/' + 'driver_' + targ_driv + '.csv'\n",
    "        #print full_path\n",
    "        target = sc.textFile(path + '/' + 'driver_' + targ_driv + '.csv') #load target driver's data\n",
    "        target2 = target.map(lambda x: x.split(',')) #convert from string to list of strings\n",
    "        positives = processRDD(target2, 1.0) #label target driver's RDD\n",
    "        driv_lis = get_drivers(path) #get python list of all possible drivers to sample from\n",
    "        #print driv_lis\n",
    "        sampdriv, samptrip = random_samples(targ_driv, driv_lis, K) #generate random samples of drivers and tripIDs\n",
    "        samples = sample_data(path, sampdriv, samptrip) #generate RDD of random samples\n",
    "        #print \"GETS HERE\"\n",
    "        samplesRDD = ID_Data(targ_driv, samples, K) #relabel samples to look like target driver's trips\n",
    "        #print \"GETS HERE TOO\"\n",
    "        negatives = processRDD(samplesRDD, 0.0) #label samples\n",
    "        finalRDD = positives.union(negatives).cache() #join target driver and samples together\n",
    "        return finalRDD\n",
    "    except Exception as e:\n",
    "        print e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "path = '/Users/mayankkedia/code/kaggle/axa_telematics/sample_drivers'\n",
    "driver = '1'\n",
    "driver_1_RDD = labelRDDs('1', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######## HARRY's code for basic feature generation ##########\n",
    "\n",
    "def vectorRDD(RDD):\n",
    "    vectorRDD = RDD.map(lambda x: (x[0], ([x[1][0]], [x[1][1]], x[1][2], (x[1][3], 1))))\\\n",
    "                    .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\\\n",
    "                    .map(lambda x: (x[0], (x[1][0], x[1][1], 1)) if int(x[0][1])\\\n",
    "                           < 201 else (x[0], (x[1][0], x[1][1], 0)))\n",
    "    return vectorRDD\n",
    "\n",
    "VectorRDD = vectorRDD(driver_1_RDD).map(lambda x: (x[0], (zip(x[1][0], [0.0] + x[1][0][:-1]), \n",
    "                                zip(x[1][1], [0.0] + x[1][1][:-1]))))\\\n",
    "         .map(lambda x: (x[0], zip(map(lambda x: (x[0] - x[1]) ** 2, x[1][0]), \n",
    "                                   map(lambda x: (x[0] - x[1]) ** 2, x[1][1]))))\\\n",
    "         .map(lambda x: (x[0], map(lambda x: (x[0] + x[1]) ** 0.5, x[1])))\\\n",
    "         .map(lambda x: (x[0], zip(x[1], [0.0] + x[1][:-1])))\\\n",
    "         .map(lambda x: (x[0], map(lambda x: ([x[0]], [x[0] - x[1]]), x[1])))\\\n",
    "         .map(lambda x: (x[0], reduce(lambda x, y: (x[0] + y[0], x[1] + y[1]), x[1])))\\\n",
    "         .map(lambda x: (x[0], (min(x[1][0]), max(x[1][0]), min(x[1][1]), max(x[1][1]))))\n",
    "# computes previous points of each x, y coordinate\n",
    "# computes distance in each x, y direction squared from previous point\n",
    "# computes euclidean distance from previous point (also speed as in m/s)\n",
    "# computes previous speed\n",
    "# computes speed difference (acceleration)\n",
    "# IF REDUCING A LIST OF TUPLES, MUST USE BOTH TUPLE ELEMENTS!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### MODELING using Gradient boosted trees with only a very minimal set of features ##########\n",
    "\n",
    "def create_labelled_vectors(x):\n",
    "    label = 1.0\n",
    "    if int(x[0][1]) > 200:\n",
    "        label = 0.0\n",
    "    return LabeledPoint(label, x[1])\n",
    "total_data = VectorRDD.map(create_labelled_vectors)\n",
    "(trainingData, testData) = total_data.randomSplit([0.7, 0.3])\n",
    "model = GradientBoostedTrees.trainClassifier(trainingData, categoricalFeaturesInfo={}, numIterations=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.282442748092\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testData.map(lambda x:x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v,p): v!=p).count()/float(testData.count())\n",
    "print 'Test Error = {}'.format(testErr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### Code to create spark data frame from Su's sampled RDD #############\n",
    "\n",
    "def combine_tuples(row):\n",
    "    data = row[1]\n",
    "    x = []\n",
    "    y = []\n",
    "    steps = []\n",
    "    label = None\n",
    "    for d in data:\n",
    "        x.append(d[0])\n",
    "        y.append(d[1])\n",
    "        steps.append(d[2])\n",
    "        label = d[3]\n",
    "    return Row(label=label,signature={\"x\":x, \"y\":y, \"steps\":steps})\n",
    "path = '/Users/mayankkedia/code/kaggle/axa_telematics/sample_drivers'\n",
    "driver = '1'\n",
    "driver_1_RDD = labelRDDs('1', path).groupByKey().map(lambda x: combine_tuples(x))\n",
    "driver_1_df = sqlContext.createDataFrame(driver_1_RDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(label=0.0, signature={u'y': [0.0, 5.6, 10.6, 15.2, 23.4, 32.4, 43.9, 55.4, 66.9, 79.8, 93.2, 106.0, 119.2, 133.3, 148.8, 162.7, 177.0, 192.7, 209.2, 225.6, 241.3, 260.1, 279.4, 296.1, 311.5, 329.5, 347.7, 362.5, 374.9, 388.3, 403.4, 421.7, 437.6, 456.4, 468.8, 482.9, 486.7, 495.8, 506.5, 515.8, 526.8, 540.1, 554.5, 566.8, 578.3, 590.9, 602.2, 614.5, 626.8, 638.8, 650.8, 663.2, 674.6, 685.2, 700.5, 714.4, 727.9, 741.6, 756.1, 770.1, 784.1, 798.0, 811.5, 825.2, 838.1, 851.6, 862.9, 874.0, 887.0, 899.2, 912.1, 924.6, 937.7, 950.8, 965.4, 979.6, 993.6, 1006.3, 1016.1, 1025.2, 1030.3, 1034.2, 1039.6, 1045.7, 1052.6, 1060.0, 1067.5, 1075.9, 1084.8, 1092.9, 1099.8, 1105.5, 1109.4, 1111.8, 1113.4, 1114.6, 1117.9, 1122.6, 1128.9, 1135.6, 1141.7, 1146.5, 1149.9, 1152.5, 1153.5, 1153.8, 1153.8, 1154.0, 1154.0, 1154.1, 1154.3, 1154.3, 1154.5, 1154.8, 1154.7, 1154.6, 1154.7, 1154.9, 1154.8, 1155.0, 1154.7, 1154.7, 1154.4, 1154.4, 1154.4, 1154.3, 1154.3, 1154.3, 1154.3, 1154.0, 1154.0, 1154.0, 1153.7, 1153.7, 1153.7, 1153.7, 1153.7, 1153.7, 1154.0, 1153.7, 1154.0, 1154.3, 1154.7, 1154.9, 1155.2, 1155.2, 1155.2, 1154.9, 1154.6, 1154.6, 1154.7, 1154.7, 1154.7, 1154.4, 1154.4, 1154.5, 1154.5, 1154.4, 1154.4, 1154.4, 1154.4, 1154.5, 1154.1, 1154.1, 1154.1, 1154.1, 1153.9, 1153.9, 1153.7, 1153.7, 1153.7, 1153.8, 1153.8, 1153.5, 1153.5, 1153.5, 1153.5, 1153.3, 1153.3, 1153.3, 1153.1, 1152.8, 1152.8, 1152.8, 1152.7, 1152.7, 1152.4, 1153.2, 1155.3, 1158.4, 1163.3, 1169.4, 1175.6, 1181.3, 1185.5, 1189.4, 1191.9, 1193.2, 1193.9, 1194.0, 1194.0, 1192.9, 1191.6, 1190.8, 1190.6, 1190.0, 1189.4, 1186.7, 1182.9, 1177.9, 1172.1, 1165.5, 1157.7, 1148.8, 1139.7, 1130.5, 1120.6, 1110.4, 1100.0, 1089.7, 1079.3, 1069.4, 1059.8, 1050.3, 1040.3, 1030.0, 1019.4, 1008.5, 996.8, 985.4, 973.3, 961.1, 947.6, 933.7, 918.9, 903.3, 887.3, 871.2, 853.8, 836.4, 818.9, 801.8, 785.1, 768.9, 753.5, 739.3, 725.0, 711.2, 697.7, 684.0, 670.4, 656.7, 642.8, 628.2, 613.4, 598.4, 582.9, 567.6, 552.1, 536.9, 521.8, 507.0, 492.3, 477.8, 464.0, 450.2, 436.7, 423.3, 409.6, 396.5, 383.9, 371.5, 358.9, 346.2, 333.8, 321.0, 308.2, 294.2, 280.3, 266.5, 251.7, 236.0, 220.4, 204.6, 189.2, 174.5, 160.0, 145.8, 132.5, 119.3, 106.8, 94.3, 82.5, 70.8, 59.4, 48.6, 38.5, 29.1, 20.3, 11.9, 4.4, -2.7, -8.8, -12.9, -16.2, -20.0, -24.7, -31.1, -37.9, -45.1, -53.3, -62.2, -71.1, -79.0, -86.5, -92.8, -97.5, -99.7, -100.0, -99.4, -98.8, -98.7, -98.5, -98.3, -98.1, -97.7, -97.4, -97.3, -97.0, -96.9, -96.8, -96.8, -96.7, -96.6, -96.5, -96.4, -96.4, -96.3, -96.2, -96.1, -95.9, -96.0, -95.9, -95.8, -95.7, -95.7, -95.6, -95.5, -95.4, -95.3, -95.2, -95.1, -95.1, -95.0, -94.9, -94.8, -94.8, -94.8, -94.6, -94.6, -94.6, -94.6, -94.6, -94.6, -94.6, -94.6, -94.5, -94.5, -94.5, -94.5, -94.5, -94.5, -94.5, -94.5, -94.5, -94.5, -94.5], u'x': [0.0, 0.9, 2.4, 4.6, 7.9, 12.2, 17.4, 22.4, 27.6, 34.0, 40.3, 46.7, 53.0, 59.4, 66.1, 71.8, 77.6, 83.1, 88.5, 93.4, 98.4, 103.1, 107.5, 112.2, 116.7, 121.0, 125.0, 128.6, 132.4, 135.8, 140.2, 144.7, 149.6, 154.3, 158.8, 163.2, 166.7, 170.8, 175.4, 180.6, 185.5, 190.2, 195.6, 200.7, 205.6, 210.8, 216.0, 221.6, 227.0, 232.2, 237.9, 243.9, 250.2, 255.9, 262.3, 266.6, 268.6, 269.0, 269.7, 269.9, 270.0, 269.7, 269.1, 268.5, 267.1, 265.7, 264.8, 264.6, 265.5, 266.3, 268.9, 271.8, 274.5, 276.6, 279.5, 282.1, 284.2, 287.1, 289.1, 291.3, 292.9, 294.6, 296.8, 297.5, 297.6, 297.9, 297.8, 297.4, 297.4, 296.8, 296.6, 296.9, 297.0, 297.2, 297.6, 297.4, 297.7, 297.7, 297.3, 297.0, 296.5, 295.8, 295.2, 295.3, 295.0, 295.4, 295.7, 296.3, 296.9, 297.3, 297.7, 298.1, 298.6, 299.2, 299.2, 299.3, 299.6, 299.9, 300.0, 300.4, 300.1, 300.1, 299.8, 299.8, 299.8, 299.6, 299.6, 299.6, 299.6, 299.0, 299.0, 299.0, 298.6, 298.6, 298.6, 298.6, 298.6, 298.6, 299.0, 298.6, 299.0, 299.6, 300.1, 300.5, 300.8, 300.8, 300.8, 300.5, 300.1, 300.1, 300.1, 300.1, 300.1, 299.8, 299.8, 299.7, 299.7, 299.5, 299.4, 299.4, 299.4, 299.4, 298.9, 298.9, 298.9, 298.9, 298.4, 298.4, 298.2, 298.2, 298.2, 298.1, 298.1, 297.8, 297.8, 297.8, 297.8, 297.5, 297.5, 297.5, 297.0, 296.5, 296.2, 296.1, 295.7, 295.7, 295.3, 295.3, 295.9, 296.4, 297.4, 297.9, 297.2, 295.8, 294.1, 293.9, 294.4, 295.0, 295.5, 295.3, 295.3, 295.3, 294.6, 294.2, 294.4, 294.8, 296.8, 298.9, 300.7, 301.0, 301.3, 301.3, 301.2, 300.5, 300.2, 300.1, 299.6, 299.3, 299.0, 298.9, 298.7, 299.1, 299.8, 299.9, 298.8, 296.6, 293.8, 291.4, 289.9, 288.6, 287.1, 286.0, 284.3, 282.3, 279.5, 277.1, 274.6, 273.4, 272.4, 272.5, 272.9, 273.5, 273.9, 274.3, 274.4, 274.4, 273.6, 271.7, 267.7, 262.1, 255.5, 248.7, 241.9, 235.4, 229.2, 223.1, 217.1, 211.5, 205.8, 200.5, 194.9, 189.2, 184.0, 179.0, 174.3, 169.5, 164.5, 159.6, 154.6, 150.0, 145.3, 140.6, 135.8, 131.2, 126.9, 122.9, 119.0, 115.4, 111.9, 108.1, 103.5, 99.1, 95.3, 90.3, 85.1, 79.8, 73.9, 68.2, 63.0, 57.7, 52.5, 46.7, 41.0, 35.1, 29.4, 24.3, 19.6, 14.8, 11.0, 7.9, 7.3, 8.3, 11.6, 16.8, 23.3, 29.1, 33.8, 36.1, 35.9, 34.9, 33.3, 30.6, 28.0, 26.1, 25.1, 24.7, 23.1, 19.9, 16.3, 13.9, 13.1, 13.0, 12.9, 12.7, 12.5, 12.5, 12.3, 12.1, 11.9, 11.8, 11.7, 11.7, 11.6, 11.6, 11.5, 11.4, 11.4, 11.3, 11.2, 11.2, 11.0, 10.8, 10.7, 10.7, 10.6, 10.5, 10.4, 10.4, 10.6, 10.5, 10.4, 10.3, 10.3, 10.3, 10.1, 10.1, 10.1, 10.1, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.9, 9.8, 9.8, 9.8, 9.8, 9.8], u'steps': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 346.0, 347.0, 348.0, 349.0, 350.0, 351.0, 352.0, 353.0, 354.0, 355.0, 356.0, 357.0, 358.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0]})]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver_1_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
